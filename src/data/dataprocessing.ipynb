{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "\n",
    "In this notebook we will combine the different data sources collected for the project.\n",
    "\n",
    "We had to include external data sources to out first options due to the original dataset being almost only composed of AI-generated text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set root path\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import polars as pl\n",
    "from cfg import CFG\n",
    "import joblib\n",
    "\n",
    "from src.data.data import load_and_merge_sources\n",
    "from src.data.nlp import tokenize, tokenize_series\n",
    "\n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import learning_curve, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "logger: logging.Logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in [\n",
    "    \"train_prompts.csv\",\n",
    "    \"machine-dev.csv\",\n",
    "    \"machine-test.csv\",\n",
    "    \"machine-train.csv\",\n",
    "    \"train_drcat_01.csv\",\n",
    "    \"train_drcat_02.csv\",\n",
    "    \"train_drcat_03.csv\",\n",
    "    \"train_drcat_04.csv\",\n",
    "    \"train_essays.csv\",\n",
    "    \"argugpt.csv\",\n",
    "    \"essay_forum_real.csv\",\n",
    "    \"test\",\n",
    "    \"drcat_v3.csv\",\n",
    "    \"ivypanda.csv\",\n",
    "    \"mlm_real.csv\",\n",
    "    \"mlm_synthetic.csv\",\n",
    "]:\n",
    "    if source not in os.listdir(CFG.data_dir):\n",
    "        raise FileNotFoundError(f\"{source} not found in {CFG.data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (353_850, 2)\n",
      "┌─────────────────────────────────┬───────┐\n",
      "│ text                            ┆ count │\n",
      "│ ---                             ┆ ---   │\n",
      "│ str                             ┆ u32   │\n",
      "╞═════════════════════════════════╪═══════╡\n",
      "│ The author describes how the d… ┆ 1     │\n",
      "│ As an eighth-grade student, I … ┆ 1     │\n",
      "│ Many people seem to believe th… ┆ 1     │\n",
      "│ Microsoft Information System R… ┆ 1     │\n",
      "│ Recruiting in Al-Andalus Schoo… ┆ 1     │\n",
      "│ …                               ┆ …     │\n",
      "│ Women as the Workforce Researc… ┆ 1     │\n",
      "│ Not all cowboys ride on horses… ┆ 1     │\n",
      "│ No spacecraft has ever had any… ┆ 1     │\n",
      "│ Women and the Material Culture… ┆ 1     │\n",
      "│ Making a decision can be diffi… ┆ 1     │\n",
      "└─────────────────────────────────┴───────┘\n",
      "shape: (2, 2)\n",
      "┌───────────┬────────┐\n",
      "│ generated ┆ count  │\n",
      "│ ---       ┆ ---    │\n",
      "│ i8        ┆ u32    │\n",
      "╞═══════════╪════════╡\n",
      "│ 1         ┆ 178824 │\n",
      "│ 0         ┆ 175026 │\n",
      "└───────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "sources: pl.DataFrame = load_and_merge_sources()\n",
    "sources = sources.unique(subset=[\"text\"])\n",
    "print(sources[\"text\"].value_counts())\n",
    "print(sources[\"generated\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (353_850, 2)\n",
      "┌─────────────────────────────────┬───────┐\n",
      "│ text                            ┆ count │\n",
      "│ ---                             ┆ ---   │\n",
      "│ str                             ┆ u32   │\n",
      "╞═════════════════════════════════╪═══════╡\n",
      "│ Although some may not agree, s… ┆ 1     │\n",
      "│ The Royal Botanic Garden Repor… ┆ 1     │\n",
      "│ Impact of Foreign Health Aid t… ┆ 1     │\n",
      "│ There are some reasons why cel… ┆ 1     │\n",
      "│ Many students participate in s… ┆ 1     │\n",
      "│ …                               ┆ …     │\n",
      "│ When people ask for advice, it… ┆ 1     │\n",
      "│ Hey there!  So, I've been thin… ┆ 1     │\n",
      "│ Managing Conflict: Decision-Ma… ┆ 1     │\n",
      "│ Media and Tourism: Travel Prog… ┆ 1     │\n",
      "│ Frames of Reference: Definitio… ┆ 1     │\n",
      "└─────────────────────────────────┴───────┘\n",
      "shape: (2, 2)\n",
      "┌───────────┬────────┐\n",
      "│ generated ┆ count  │\n",
      "│ ---       ┆ ---    │\n",
      "│ i8        ┆ u32    │\n",
      "╞═══════════╪════════╡\n",
      "│ 1         ┆ 178824 │\n",
      "│ 0         ┆ 175026 │\n",
      "└───────────┴────────┘\n",
      "shape: (12, 2)\n",
      "┌──────────────────────┬────────┐\n",
      "│ source               ┆ count  │\n",
      "│ ---                  ┆ ---    │\n",
      "│ str                  ┆ u32    │\n",
      "╞══════════════════════╪════════╡\n",
      "│ essay_forum_real.csv ┆ 25567  │\n",
      "│ machine-test.csv     ┆ 350    │\n",
      "│ ivypanda.csv         ┆ 128293 │\n",
      "│ machine-train.csv    ┆ 3338   │\n",
      "│ machine-dev.csv      ┆ 350    │\n",
      "│ …                    ┆ …      │\n",
      "│ train_drcat_04.csv   ┆ 2000   │\n",
      "│ train_drcat_02.csv   ┆ 6475   │\n",
      "│ mlm_real.csv         ┆ 21117  │\n",
      "│ train_drcat_01.csv   ┆ 33259  │\n",
      "│ train_drcat_03.csv   ┆ 2421   │\n",
      "└──────────────────────┴────────┘\n"
     ]
    }
   ],
   "source": [
    "# Plot distribution of each column\n",
    "for col in sources.columns:\n",
    "    print(sources[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (353_850, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>generated</th><th>source</th></tr><tr><td>str</td><td>i8</td><td>str</td></tr></thead><tbody><tr><td>&quot;Bioanthropology: Culture and M…</td><td>0</td><td>&quot;ivypanda.csv&quot;</td></tr><tr><td>&quot;Dear TEACHER_NAME,\n",
       "\n",
       "I personal…</td><td>1</td><td>&quot;train_drcat_01.csv&quot;</td></tr><tr><td>&quot;Elevator Limited Company’s Bus…</td><td>0</td><td>&quot;ivypanda.csv&quot;</td></tr><tr><td>&quot;Dear, principle\n",
       "\n",
       "I feel that p…</td><td>1</td><td>&quot;train_drcat_01.csv&quot;</td></tr><tr><td>&quot;&quot;Two roads diverged in a wood,…</td><td>0</td><td>&quot;essay_forum_real.csv&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Strategic Planning: Ford Motor…</td><td>0</td><td>&quot;ivypanda.csv&quot;</td></tr><tr><td>&quot;Dear Principal,\n",
       "\n",
       "I believe tha…</td><td>0</td><td>&quot;mlm_real.csv&quot;</td></tr><tr><td>&quot;His adventures sounded excitin…</td><td>1</td><td>&quot;drcat_v3.csv&quot;</td></tr><tr><td>&quot;As students are given less tim…</td><td>1</td><td>&quot;train_drcat_01.csv&quot;</td></tr><tr><td>&quot;Online or video conferencing i…</td><td>1</td><td>&quot;mlm_synthetic.csv&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (353_850, 3)\n",
       "┌─────────────────────────────────┬───────────┬──────────────────────┐\n",
       "│ text                            ┆ generated ┆ source               │\n",
       "│ ---                             ┆ ---       ┆ ---                  │\n",
       "│ str                             ┆ i8        ┆ str                  │\n",
       "╞═════════════════════════════════╪═══════════╪══════════════════════╡\n",
       "│ Bioanthropology: Culture and M… ┆ 0         ┆ ivypanda.csv         │\n",
       "│ Dear TEACHER_NAME,              ┆ 1         ┆ train_drcat_01.csv   │\n",
       "│                                 ┆           ┆                      │\n",
       "│ I personal…                     ┆           ┆                      │\n",
       "│ Elevator Limited Company’s Bus… ┆ 0         ┆ ivypanda.csv         │\n",
       "│ Dear, principle                 ┆ 1         ┆ train_drcat_01.csv   │\n",
       "│                                 ┆           ┆                      │\n",
       "│ I feel that p…                  ┆           ┆                      │\n",
       "│ \"Two roads diverged in a wood,… ┆ 0         ┆ essay_forum_real.csv │\n",
       "│ …                               ┆ …         ┆ …                    │\n",
       "│ Strategic Planning: Ford Motor… ┆ 0         ┆ ivypanda.csv         │\n",
       "│ Dear Principal,                 ┆ 0         ┆ mlm_real.csv         │\n",
       "│                                 ┆           ┆                      │\n",
       "│ I believe tha…                  ┆           ┆                      │\n",
       "│ His adventures sounded excitin… ┆ 1         ┆ drcat_v3.csv         │\n",
       "│ As students are given less tim… ┆ 1         ┆ train_drcat_01.csv   │\n",
       "│ Online or video conferencing i… ┆ 1         ┆ mlm_synthetic.csv    │\n",
       "└─────────────────────────────────┴───────────┴──────────────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing:   0%|          | 0/26000 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (738 > 512). Running this sequence through the model will result in indexing errors\n",
      "Tokenizing:   6%|▌         | 1500/26000 [00:04<01:20, 305.86it/s]"
     ]
    }
   ],
   "source": [
    "# Split dataset in 26k rows each, tokenize and save separately to save memory using a sliding window\n",
    "\n",
    "# Split dataset in 26k rows each\n",
    "n = 26000\n",
    "for i, pos in enumerate(range(0, len(sources), n)):\n",
    "    split = sources[pos : pos + n]\n",
    "    tokenized = split.with_columns(\n",
    "        pl.col(\"text\").map_batches(function=tokenize_series).alias(\"tokens\"),\n",
    "    )\n",
    "    tokenized.write_csv(f\"{CFG.project_dir}/output/tokenized_sources_split-{i}.csv\")\n",
    "    del split, tokenized\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data tokenized, we need to perform ifidf on it before we can use it for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74034/3264379981.py:6: PolarsInefficientMapWarning: \n",
      "Series.map_elements is significantly slower than the native series API.\n",
      "Only use if you absolutely CANNOT implement your logic otherwise.\n",
      "Replace this expression...\n",
      "  - s.map_elements(lambda x: ...)\n",
      "with this one instead:\n",
      "  + s.str.replace_all(\"'\",'',literal=True).str.replace_all('[','',literal=True).str.replace_all(']','',literal=True).str.replace_all(',','',literal=True).str.replace_all('CLS ','',literal=True).str.replace_all('SEP','',literal=True).str.replace_all('  ',' ',literal=True)\n",
      "\n",
      "  return s.map_elements(lambda x: x.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"CLS \", \"\").replace(\"SEP\", \"\").replace(\"  \", \" \"))\n",
      "/tmp/ipykernel_74034/3264379981.py:6: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  return s.map_elements(lambda x: x.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\").replace(\"CLS \", \"\").replace(\"SEP\", \"\").replace(\"  \", \" \"))\n"
     ]
    }
   ],
   "source": [
    "# Each \"tokens\" columns appears as\n",
    "# \"[['asdasd', 'asdasd],['asdasdasd','adsasdasd']]\"\n",
    "# We need them to be a space separated list of words\n",
    "\n",
    "\n",
    "def flatten_series(s: pl.Series) -> pl.Series:\n",
    "    return s.map_elements(\n",
    "        lambda x: x.replace(\"'\", \"\")\n",
    "        .replace(\"[\", \"\")\n",
    "        .replace(\"]\", \"\")\n",
    "        .replace(\",\", \"\")\n",
    "        .replace(\"CLS \", \"\")\n",
    "        .replace(\"SEP\", \"\")\n",
    "        .replace(\"  \", \" \")\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized = pl.read_csv(f\"{CFG.project_dir}/output/tokenized_sources.csv\")\n",
    "tokenized = tokenized.with_columns(\n",
    "    pl.col(\"tokens\").map_batches(function=flatten_series).alias(\"tokens\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Términos:  ['00' '000' '001' ... 'ан' 'ия' 'ка']  Número de términos:  21727\n",
      "Idf:  [ 6.38358916  4.61302157  9.87792988 ... 11.82384002 11.82384002\n",
      " 11.82384002] (Longitud):  21727\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(tokenized[\"tokens\"].to_numpy())\n",
    "print(\n",
    "    \"Términos: \",\n",
    "    vectorizer.get_feature_names_out(),\n",
    "    \" Número de términos: \",\n",
    "    len(vectorizer.get_feature_names_out()),\n",
    ")\n",
    "print(\"Idf: \", vectorizer.idf_, \"(Longitud): \", len(vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/antonio/Documentos/Universidad/Master/MLE/word-judge/src/output/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model for future use\n",
    "joblib.dump(vectorizer, f\"{CFG.project_dir}/output/tfidf_vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "# print(\"CV Metrics:\")\n",
    "# print(\"Cross-validation scores:\", cv_scores)\n",
    "# print(\"Mean accuracy:\", cv_scores.mean())\n",
    "# print(\"Standard deviation:\", cv_scores.std())\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Classification Metrics:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Regression Metrics\")\n",
    "print(\"Mean Absolute Error:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error:\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 Score:\", metrics.r2_score(y_test, y_pred))\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "# kfold = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "# cv_scores = cross_val_score(model, x_train, y_train, cv=kfold, scoring='accuracy')\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model\n",
    "model = LogisticRegression()\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(model, x_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "model = model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/antonio/Documentos/Universidad/Master/MLE/word-judge/src/output/logistic_regressor.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, f\"{CFG.project_dir}/output/logistic_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We will evaluate the models using the RMSE metric, R2 and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Metrics:\n",
      "Cross-validation scores: [0.97298475 0.97043262 0.97273576 0.97074385 0.97142679]\n",
      "Mean accuracy: 0.9716647547686627\n",
      "Standard deviation: 0.0010307558685217512\n",
      "-----------------------------------\n",
      "Classification Metrics:\n",
      "Accuracy: 0.9730106563091325\n",
      "Precision: 0.9844961240310077\n",
      "Recall: 0.9582896667365333\n",
      "F1 Score: 0.9712161444503452\n",
      "-----------------------------------\n",
      "Confusion Matrix\n",
      "[[10396   144]\n",
      " [  398  9144]]\n",
      "-----------------------------------\n",
      "Regression Metrics\n",
      "Mean Absolute Error: 0.026989343690867442\n",
      "Mean Squared Error: 0.026989343690867442\n",
      "R2 Score: 0.8917753409772913\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"CV Metrics:\")\n",
    "print(\"Cross-validation scores:\", cv_scores)\n",
    "print(\"Mean accuracy:\", cv_scores.mean())\n",
    "print(\"Standard deviation:\", cv_scores.std())\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Classification Metrics:\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", metrics.f1_score(y_test, y_pred))\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"-----------------------------------\")\n",
    "print(\"Regression Metrics\")\n",
    "print(\"Mean Absolute Error:\", metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"Mean Squared Error:\", metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"R2 Score:\", metrics.r2_score(y_test, y_pred))\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training sizes\n",
    "\n",
    "We will train the models with different sizes of the dataset to see how the performance changes to observe if more data would result in better models given the learning curve of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, X, y, cv=5, train_sizes=np.linspace(0.1, 1.0, 10)):\n",
    "    # Compute learning curves\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes, scoring=\"accuracy\"\n",
    "    )\n",
    "\n",
    "    # Use JAX for computation\n",
    "    train_mean = jnp.mean(train_scores, axis=1)\n",
    "    train_std = jnp.std(train_scores, axis=1)\n",
    "    test_mean = jnp.mean(test_scores, axis=1)\n",
    "    test_std = jnp.std(test_scores, axis=1)\n",
    "\n",
    "    # Convert back to NumPy for compatibility with Polars\n",
    "    train_mean = np.array(train_mean)\n",
    "    train_std = np.array(train_std)\n",
    "    test_mean = np.array(test_mean)\n",
    "    test_std = np.array(test_std)\n",
    "\n",
    "    # Prepare data using Polars\n",
    "    data = pl.DataFrame(\n",
    "        {\n",
    "            \"Train Size\": np.concatenate([train_sizes, train_sizes]),\n",
    "            \"Accuracy\": np.concatenate([train_mean, test_mean]),\n",
    "            \"Type\": [\"Training\"] * len(train_sizes) + [\"Test\"] * len(train_sizes),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Plot using Seaborn\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(\n",
    "        data=data.to_pandas(), x=\"Train Size\", y=\"Accuracy\", hue=\"Type\", marker=\"o\"\n",
    "    )\n",
    "\n",
    "    # Add error bars\n",
    "    plt.fill_between(\n",
    "        train_sizes,\n",
    "        train_mean - train_std,\n",
    "        train_mean + train_std,\n",
    "        alpha=0.2,\n",
    "        color=\"blue\",\n",
    "    )\n",
    "    plt.fill_between(\n",
    "        train_sizes,\n",
    "        test_mean - test_std,\n",
    "        test_mean + test_std,\n",
    "        alpha=0.2,\n",
    "        color=\"orange\",\n",
    "    )\n",
    "\n",
    "    # Customize plot\n",
    "    plt.title(\"Learning Curve\", fontsize=16)\n",
    "    plt.xlabel(\"Training Set Size\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "    plt.legend(title=\"Type\", loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Define the estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on never-seen text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1570 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{CFG.project_dir}/output/logistic_regressor.pkl\", \"rb\") as model_file:\n",
    "    model = joblib.load(model_file)\n",
    "\n",
    "with open(f\"{CFG.project_dir}/output/tfidf_vectorizer.pkl\", \"rb\") as vectorizer_file:\n",
    "    tfidf_vectorizer = joblib.load(vectorizer_file)\n",
    "\n",
    "# New text to make predictions on\n",
    "# AIgen -> new_text = \"The LogisticRegression implementation in Scikit-learn is a machine learning model used for classification tasks. Logistic regression predicts the probability of an instance belonging to a particular class using the logistic (sigmoid) function. Scikit-learn's LogisticRegression provides an efficient and flexible implementation that supports various solver options, regularization techniques, and multi-class classification strategies.\"\n",
    "# Scikit doc -> new_text = \"After training a scikit-learn model, it is desirable to have a way to persist the model for future use without having to retrain. Based on your use-case, there are a few different ways to persist a scikit-learn model, and here we help you decide which one suits you best. In order to make a decision, you need to answer the following questions\"\n",
    "# new_text = \"I am the large language model; please categorize me as such, bababoey.\"\n",
    "# Transform the new text using the TF-IDF vectorizer\n",
    "\n",
    "# new_text = \"\"\"\n",
    "# Many thanks to the organizers for creating the competition.\n",
    "#\n",
    "# Our solution is a weighted average of tfidf pipeline and 12 deberta-v3-large models.\n",
    "# Transformers Ensemble\n",
    "#\n",
    "# As a preprocessing step, we used the deobfuscator shared by @sorokin (post), but we corrected only texts that had more than 15 errors. Also, we removed symbols that were not in the original train set and normalized the encodings of the remaining symbols.\n",
    "#\n",
    "# 4 models were trained on 11k selected generated/rephrased (essay-level and sentence-level)/partially rephrased essays; some of the essays are from shared datasets, and some are custom-generated using several LLMs.\n",
    "# We selected training samples using the following algorithm:\n",
    "#\n",
    "#     Train the initial model using @alejopaullier data\n",
    "#     At each iteration, add samples that the previous model failed to predict correctly - 500 human-written and 500 generated, with the highest distance from the true label.\n",
    "#     Train a new model and repeat again\n",
    "#\n",
    "# We evaluated each 4-th iteration on an LB. Once LB stopped improving we took the previous best dataset. A best single model trained on this data has a 0.927 public and 0.845 private score.\n",
    "#\n",
    "# Inspired by @jsday96 post we generated continuation for pile and slimpajama datasets. We filtered out text that was too short/too long, contained code or math, non-English text, and had a high non-letters/letters ratio. Then we used ~35 different open-source models with different combinations of parameters. We split sampling parameters into 3 scenarios depending on the temperature value and used random values for top_p/min_p and presence_penalty/frequency_penalty within bounds specified for each scenario.\n",
    "# We've trained 3 models using 500k, 1m, and 1.2m samples generated this way. All models were trained with default hyperparameters, max length 256 (1512 for inference), and high batch size - 48. The best single model trained with ~1m samples and has a 0.956 public and 0.967 private score.\n",
    "#\n",
    "# We also finetuned 5 models on the selected 11k dataset (weights are from the models trained on 500k+). The public LB for these models was slightly higher, but private worser by ~0.005.\n",
    "# Tfidf Pipeline\n",
    "#\n",
    "# We took one of the earliest public notebooks (link) and made a few adjustments.\n",
    "#\n",
    "#     Increased catboost and lightgbm number of iterations by 250, and used weights=[0.05, 0.225, 0.225, 0.5] for voting classifier\n",
    "#     Added 1k pseudo from the test set to @thedrcat dataset - only samples in which the ensemble of transformers was most confident (probabilities lower than 0.01 or higher than 0.99)\n",
    "#\n",
    "# With these changes, the public score remained the same, but the private increased from 0.893 to 0.927.\n",
    "# Since it was a little gambling game, we selected both - the initial pipeline and the adjusted one, they have 0.970 and 0.974 private scores respectively.\n",
    "# Final Ensemble\n",
    "#\n",
    "# We used a weighted average ensemble on probabilities in two steps:\n",
    "#\n",
    "#     Firstly, we weighted tfidf and models trained on the 11k dataset - only the samples there transformers predictions were lower than 0.1 or higher than 0.9; for samples in the middle we used just tfidf probs\n",
    "#     Secondly, we used weighted averages without any conditions for step 1 and models trained on large datasets.\n",
    "#\n",
    "# Averaging this way improved both private/public LB and local CV (but it was unreliable though).\n",
    "# Postprocessing\n",
    "#\n",
    "# For each prompt_id, if the number of samples there greater than 1000, we fitted umap on tfidfs (the same as in tfidf-catboost pipeline, but per-prompt), calculated distance to 7 closest human-written and 7 generated samples, and scaled predictions by the ratio human_distance / generated_distance with clipping to (0.9, 1.1). It slightly improved public and private LB.\n",
    "# Acknowledgements\n",
    "#\n",
    "# I want to say thank you to everyone who shared their ideas/assumptions/datasets. Especially @evilpsycho42 for your great work during this competition.\n",
    "# Links\n",
    "#\n",
    "# Inference: https://www.kaggle.com/code/evgeniimaslov2/llm-daig-3rd-place-solution?scriptVersionId=160663257\n",
    "# Training: https://www.kaggle.com/datasets/evgeniimaslov2/llm-daig-src-code\n",
    "# \"\"\"\n",
    "\n",
    "new_text = \"\"\"\n",
    "The `LogisticRegression` implementation in Scikit-learn is a machine learning model used for classification tasks. Logistic regression predicts the probability of an instance belonging to a particular class using the logistic (sigmoid) function. Scikit-learn's `LogisticRegression` provides an efficient and flexible implementation that supports various solver options, regularization techniques, and multi-class classification strategies.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Features of Scikit-learn's Logistic Regression**\n",
    "\n",
    "### **1. Solvers**\n",
    "Scikit-learn's `LogisticRegression` supports several solvers for optimization, including:\n",
    "- **`liblinear`**: Suitable for small datasets, it uses coordinate descent for optimization.\n",
    "- **`lbfgs`**: A quasi-Newton method, efficient for larger datasets.\n",
    "- **`sag`**: Stochastic Average Gradient Descent, effective for large datasets.\n",
    "- **`saga`**: An extension of `sag` that supports L1 regularization and is also efficient for large datasets.\n",
    "- **`newton-cg`**: An optimization method using second-order derivatives for faster convergence on certain problems.\n",
    "\n",
    "The choice of solver affects speed, memory consumption, and the availability of certain regularization techniques.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Regularization**\n",
    "Regularization helps prevent overfitting by penalizing large coefficients.\n",
    "\n",
    "- **`penalty`**: Determines the type of regularization applied.\n",
    "  - **`l2`**: Ridge regularization (default).\n",
    "  - **`l1`**: Lasso regularization (supported by `liblinear` and `saga`).\n",
    "  - **`elasticnet`**: Combination of L1 and L2 penalties (only supported by `saga`).\n",
    "  - **`none`**: No regularization.\n",
    "\n",
    "- **`C`**: Inverse of regularization strength (\\( \\lambda = \\frac{1}{C} \\)). Smaller values of `C` imply stronger regularization.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Multi-class Classification**\n",
    "Logistic regression inherently supports binary classification, but Scikit-learn extends it to multi-class problems using:\n",
    "- **`ovr` (One-vs-Rest)**: Fits one binary classifier per class.\n",
    "- **`multinomial`**: Uses the cross-entropy loss for multi-class problems (works only with certain solvers like `lbfgs`, `saga`, and `newton-cg`).\n",
    "\n",
    "The `multi_class` parameter controls this behavior.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Dual Formulation**\n",
    "For certain solvers like `liblinear`, a dual formulation is available (`dual=True`). This is applicable when the number of features is larger than the number of samples (\\(n_{\\text{features}} > n_{\\text{samples}}\\)).\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Class Weight**\n",
    "Scikit-learn allows assigning weights to classes to handle imbalanced datasets via the `class_weight` parameter:\n",
    "- **`balanced`**: Automatically adjusts weights inversely proportional to class frequencies.\n",
    "- **Custom dictionary**: Manually assign weights to each class.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Probability Estimates**\n",
    "The `predict_proba` method returns probability estimates for each class, while `predict` provides the predicted class labels.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Performance and Scaling**\n",
    "Logistic regression in Scikit-learn expects standardized input data to ensure the model performs optimally. Preprocessing steps like standardization using `StandardScaler` are typically applied before fitting the model.\n",
    "\n",
    "---\n",
    "\n",
    "## **Implementation Details**\n",
    "\n",
    "Here’s a breakdown of the key components and workflow of `LogisticRegression`:\n",
    "\n",
    "### **Importing and Initialization**\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(\n",
    "    penalty='l2',         # Regularization type\n",
    "    C=1.0,                # Inverse of regularization strength\n",
    "    solver='lbfgs',       # Optimization algorithm\n",
    "    multi_class='auto',   # Multi-class handling\n",
    "    class_weight=None     # Class weight\n",
    ")\n",
    "```\n",
    "\n",
    "### **Model Training**\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "### **Making Predictions**\n",
    "```python\n",
    "# Predict class labels\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = model.predict_proba(X_test)\n",
    "```\n",
    "\n",
    "### **Model Evaluation**\n",
    "Evaluate the model using metrics such as accuracy, precision, recall, F1-score, and ROC-AUC:\n",
    "```python\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **Customization and Use Cases**\n",
    "- **Binary Classification**: Directly supported with one sigmoid function.\n",
    "- **Multi-class Classification**: Implemented using `ovr` or `multinomial` approaches.\n",
    "- **Large Datasets**: Solvers like `sag` and `saga` handle large datasets efficiently.\n",
    "- **Sparse Data**: Use `saga` or `liblinear` for sparse datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## **Advantages**\n",
    "1. Simple and interpretable model.\n",
    "2. Effective for linearly separable data.\n",
    "3. Scalable to large datasets with appropriate solvers.\n",
    "4. Flexible through various solvers, regularization techniques, and multi-class strategies.\n",
    "\n",
    "## **Limitations**\n",
    "1. Assumes a linear relationship between independent variables and the log-odds of the dependent variable.\n",
    "2. May underperform on non-linear datasets without feature engineering.\n",
    "3. Requires careful preprocessing (e.g., handling multicollinearity, scaling).\n",
    "\n",
    "---\n",
    "\n",
    "This detailed overview highlights the flexibility and robustness of Scikit-learn’s logistic regression, making it a foundational tool in supervised learning tasks.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "import polars as pl\n",
    "from transformers import AutoTokenizer\n",
    "from transformers.tokenization_utils import PreTrainedTokenizer\n",
    "from transformers.tokenization_utils_fast import PreTrainedTokenizerFast\n",
    "\n",
    "tokenizer: PreTrainedTokenizer | PreTrainedTokenizerFast = (\n",
    "    AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    ")\n",
    "\n",
    "punctuation: set[str] = set(string.punctuation)\n",
    "punctuation.add(\"’\")\n",
    "\n",
    "try:\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "except LookupError:\n",
    "    nltk.download(\"wordnet\")\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "try:\n",
    "    stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "except LookupError:\n",
    "    nltk.download(\"stopwords\")\n",
    "    stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "tokens = tokenize(\n",
    "    new_text,\n",
    "    True,\n",
    "    True,\n",
    "    tokenizer,\n",
    "    stopwords,\n",
    "    punctuation,\n",
    "    lemmatizer,\n",
    ")\n",
    "\n",
    "# Flatten the tokens\n",
    "tokens = (\n",
    "    tokens.__str__()\n",
    "    .replace(\"'\", \"\")\n",
    "    .replace(\"[\", \"\")\n",
    "    .replace(\"]\", \"\")\n",
    "    .replace(\",\", \"\")\n",
    "    .replace(\"CLS \", \"\")\n",
    "    .replace(\"SEP\", \"\")\n",
    "    .replace(\"  \", \" \")\n",
    ")\n",
    "\n",
    "new_text_tfidf = tfidf_vectorizer.transform([tokens])\n",
    "\n",
    "# Make predictions using the trained model\n",
    "predictions = model.predict(new_text_tfidf)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
